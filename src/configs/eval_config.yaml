# Evaluation configuration file for PSO
# Usage: python src/eval.py model_path=outputs/best_model.pt
# Hydra configuration
hydra:
  run:
    dir: src/outputs/eval/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: src/outputs/eval/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
model:
  name: ppo
  hidden_sizes: [64, 64]
  activation: relu
  dropout: 0.25
  learning_rate: 0.0003
  centralized_critic: true
  share_params: true

env:
  name: swarm
  landscape_dim: 2
  num_agents: 8
  batch_size: 1
  delta: 1.0
  landscape_function: sphere

eval:
  num_eval_episodes: 10
  max_steps: 100
  save_metrics: true
  compare_random: true

visualization:
  visualize_swarm: false
  visualize_landscape: true
  save_gif: false
  save_dir: src/outputs/vis/
  fps: 10
  dpi: 150

# Model checkpoint to evaluate
model_path: src/outputs/best_model.pt

# Output directory for evaluation results
output_dir: src/outputs/eval
